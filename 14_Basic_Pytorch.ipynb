{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akib1162100/ML_base/blob/main/14_Basic_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4oEP7VRqkHv"
      },
      "source": [
        "### 1. Pytorch Overview\n",
        "#### PyTorch is a deep learning framework and a scientific computing package. It provides a flexible and efficient way to build, train, and deploy neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR2WhCWzqkH0"
      },
      "source": [
        "### Installing PyTorch with Anaconda and Conda\n",
        "\n",
        "#### Getting started with PyTorch is very easy. The recommended best option is to use the Anaconda Python package manager.\n",
        " ##### Let's go over the steps:\n",
        "\n",
        "   * Download and install Anaconda (choose the latest Python version). (No need to install if already installed)\n",
        "   * Go to [PyTorch's site](https://pytorch.org/get-started/locally/) and find the get started locally section. (Choose CPU version)\n",
        "   * Specify the appropriate configuration options for your particular environment.\n",
        "   * Run the presented command in the terminal to install PyTorch.\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UCTgo8NqkH2"
      },
      "source": [
        "You may also RUN the following command below :\n",
        "###### command : conda install pytorch torchvision torchaudio cpuonly -c pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jVste5NqkH2"
      },
      "source": [
        "### 2. PyTorch's tensor Library\n",
        "*  A tensor is a n-dimensional array.  Tensors are super important for deep learning and neural networks because they are the data structure that we ultimately use for building and training our neural networks. On top of the tensor library, PyTorch has much more to offer in terms of building and training neural networks.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph2whA_AqkH2"
      },
      "source": [
        "### This table gives us a list of PyTorch packages and their corresponding descriptions. These are the primary PyTorch components we'll be learning about and using as we build neural networks in this course.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym6YnXX8qkH2"
      },
      "source": [
        "| Package |Description |\n",
        "| --- | --- |\n",
        "|torch | The top-level PyTorch package and tensor library |\n",
        "torch.nn | A subpackage that contains modules and extensible classes for building neural networks. |\n",
        "torch.autograd | A subpackage that supports all the differentiable Tensor operations in PyTorch. |\n",
        "torch.nn.functional | A functional interface that contains typical operations used for building neural networks like loss functions, activation functions, and convolution operations. |\n",
        "torch.optim  |\tA subpackage that contains standard optimization operations like SGD and Adam. |\n",
        "torch.utils  |\tA subpackage that contains utility classes like data sets and data loaders that make data preprocessing easier. |\n",
        "torchvision  |\tA package that provides access to popular datasets, model architectures, and image transformations for computer vision.  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdcUmylTqkH3"
      },
      "source": [
        "### 3. Pytorch Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXscQiFdqkH-"
      },
      "outputs": [],
      "source": [
        "#in order to import torch library you need to run the following command\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zSVvw4NqkIA"
      },
      "source": [
        "###### To check the version, we use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g6ajUPOqkIA",
        "outputId": "bc672b49-e8f9-4139-d50b-0fab78b12e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiUPQsLLqkIB"
      },
      "source": [
        "### Explanation of Tensors - Data Structures of Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "argzmmt0qkIB"
      },
      "source": [
        "#### What is a tensor?\n",
        "* A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
        "\n",
        "* The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU, just cast the Tensor to a cuda datatype.\n",
        "\n",
        "* The inputs, outputs, and transformations within neural networks are all represented using tensors, and as a result, neural network programming utilizes tensors heavily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeT4zsTnqkIB"
      },
      "source": [
        "### Indexes required to access an element :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A84Ka9qqkIB"
      },
      "source": [
        "| Indexes required | Computer science | Mathematics |\n",
        "| --- | --- | --- |\n",
        "| 0 | number | scalar |\n",
        "| 1 | array | vector |\n",
        "| 2 | 2d-array | matrix |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpOuK-ieqkIB"
      },
      "source": [
        "###### For example, suppose we have this array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuINXnB_qkIB"
      },
      "outputs": [],
      "source": [
        "a = [1,2,3,4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnhtlnSRqkIC"
      },
      "source": [
        "##### Now, suppose we want to access (refer to) the number in this data structure. We can do it using a single index like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAvwTvSrqkIC",
        "outputId": "8550bf47-c7d5-4b66-f24c-585e946e99e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLId-jo3qkIC"
      },
      "source": [
        "##### This logic works the same for a vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00RLrhpEqkIC"
      },
      "outputs": [],
      "source": [
        "dd = [\n",
        "[1,2,3],\n",
        "[4,5,6],\n",
        "[7,8,9]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAEL8UqwqkIC"
      },
      "source": [
        "##### Now, suppose we want to access (refer to) the number in this data structure. In this case, we need two indexes to locate the specific element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DilRkrzoqkIC",
        "outputId": "9e9e3775-40db-42d6-8c26-24aa920ba87d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[0][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCR4WZ79qkIC"
      },
      "source": [
        "###### This logic works the same for a matrix.\n",
        "###### Note that, if we have a number or scalar, we don't need an index, we can just refer to the number or scalar directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWzBK_z9qkID"
      },
      "source": [
        "### Basic Tensor Operation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al1Rj53UqkID"
      },
      "outputs": [],
      "source": [
        "# Create two tensors\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkWksx_KqkID"
      },
      "outputs": [],
      "source": [
        "# Sum of tensors\n",
        "sum_result = torch.add(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9doH2WzUqkID"
      },
      "outputs": [],
      "source": [
        "# Subtract tensors\n",
        "sub_result = torch.sub(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrOMO2IcqkID"
      },
      "outputs": [],
      "source": [
        "# Divide tensors\n",
        "div_result = torch.div(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Z0eu2HqkID"
      },
      "outputs": [],
      "source": [
        "# Multiply tensors\n",
        "mul_result = torch.mul(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eph-DpktqkID",
        "outputId": "27537521-5056-459d-f158-8203e65bfa45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor([1, 2, 3])\n",
            "y: tensor([4, 5, 6])\n",
            "Sum: tensor([5, 7, 9])\n",
            "Subtract: tensor([-3, -3, -3])\n",
            "Divide: tensor([0.2500, 0.4000, 0.5000])\n",
            "Multiply: tensor([ 4, 10, 18])\n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)\n",
        "print(\"Sum:\", sum_result)\n",
        "print(\"Subtract:\", sub_result)\n",
        "print(\"Divide:\", div_result)\n",
        "print(\"Multiply:\", mul_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0dC7qUOqkIE"
      },
      "source": [
        "## Tensors are generalizations\n",
        "* Let's look at what happens when there are more than two indexes required to access (refer to) a specific element within these data structures we have been considering.\n",
        "*  When more than two indexes are required to access a specific element, we stop giving specific names to the structures, and we begin using more general language.\n",
        "\n",
        "## Mathematics\n",
        "\n",
        "In mathematics, we stop using words like scalar, vector, and matrix, and we start using the word tensor or nd-tensor. The 'n' tells us the number of indexes required to access a specific element within the structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNu-T4JTqkIE"
      },
      "source": [
        "## Computer science\n",
        "\n",
        " In computer science, we stop using words like, number, array, 2d-array, and start using the word multidimensional array or nd-array. The 'n'  tells us the number of indexes required to access a specific element within the structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2SqnvKnqkIE"
      },
      "source": [
        "| Indexes required | Computer science | Mathematics |\n",
        "| --- | --- | --- |\n",
        "| n | nd-array  | nd-tensor  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDnoQCYlqkIE"
      },
      "source": [
        "##### Let's make this clear. For practical purposes in neural network programming, tensors and nd-arrays are one in the same.\n",
        "* ##### Tensors and nd-arrays are the same thing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCqJk9pbqkIE"
      },
      "source": [
        "So tensors are multidimensional arrays or nd-arrays for short. The reason we say a tensor is a generalization is because we use the word tensor for all values of *n* like so:\n",
        "\n",
        "* A scalar is a 0 dimensional tensor\n",
        "* A vector is a 1 dimensional tensor\n",
        "* A matrix is a 2 dimensional tensor\n",
        "* A nd-array is an n dimensional tensor\n",
        "\n",
        "###### Tensors allow us to drop these specific terms and just use a term to identify the number of dimensions we are working with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0byX5kXyqkIF"
      },
      "source": [
        "## Rank, Axes and Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO4qXGI4qkIF"
      },
      "source": [
        "The rank, axes, and shape are three tensor attributes that will concern us most when starting out with tensors in deep learning. These concepts build on one another starting with rank, then axes, and building up to shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtuB175XqkIF"
      },
      "source": [
        "### Rank of a tensor\n",
        "\n",
        "The rank of a tensor refers to the number of dimensions present within the tensor. Suppose we are told that we have a rank-2 tensor. This means all of the following:\n",
        "\n",
        "   * We have a matrix\n",
        "   * We have a 2d-array\n",
        "   * We have a 2d-tensor\n",
        "   \n",
        "##### A tensor's rank tells us how many indexes are needed to refer to a specific element within the tensor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6wYF_0qkIF"
      },
      "source": [
        "### Axes of a tensor\n",
        "If we have a tensor, and we want to refer to a specific dimension, we use the word axis in deep learning.\n",
        "###### An axis of a tensor is a specific dimension of a tensor.\n",
        "If we say that a tensor is a rank 2 tensor, we mean that the tensor has 2 dimensions, or equivalently, the tensor has two axes.\n",
        "\n",
        "### Length of an axis\n",
        "\n",
        "###### The length of each axis tells us how many indexes are available along each axis.\n",
        "Suppose we have a tensor called t, and we know that the first axis has a length of three while the second axis has a length of four.\n",
        " Since the first axis has a length of three, this means that we can index three positions along the first axis like so: \\\n",
        "`t[0] ` \\\n",
        "`t[1] ` \\\n",
        "`t[2] `\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfaUtyOeqkIM"
      },
      "outputs": [],
      "source": [
        "t = [\n",
        "[1,2,3,9],\n",
        "[4,5,6,8],\n",
        "[7,8,9,3]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5SluynWqkIM",
        "outputId": "be128cd3-d68b-4c3b-d627-e52140d22487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7, 8, 9, 3]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try accessing index 0,1 and 2. Then try to access index 3\n",
        "t[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqrMNaISqkIN"
      },
      "source": [
        "###### All of these indexes are valid, but we can't move passed index 2.\n",
        "\n",
        "Since the second axis has a length of four, we can index four positions along the second axis. This is possible for each index of the first axis, so we have:\n",
        "\n",
        "`t[0][0]` \\\n",
        "`t[1][0]` \\\n",
        "`t[2][0]`\n",
        "\n",
        "`t[0][1]` \\\n",
        "`t[1][1]` \\\n",
        "`t[2][1]`\n",
        "\n",
        "`t[0][2]` \\\n",
        "`t[1][2]` \\\n",
        "`t[2][2]`\n",
        "\n",
        "`t[0][3]` \\\n",
        "`t[1][3]` \\\n",
        "`t[2][3]`  `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tQ2I5ZNqkIN",
        "outputId": "c37a044f-c5c0-4ed0-d002-852ca6cea3ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try accessng index 4 along the second axis\n",
        "t[2][3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLdiDomhqkIO"
      },
      "source": [
        "### Tensor axes example\n",
        "\n",
        "Let's look at some examples to make this solid. We'll consider the same tensor dd as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2_RYpARqkIO"
      },
      "outputs": [],
      "source": [
        "dd = [\n",
        "[1,2,3],\n",
        "[4,5,6],\n",
        "[7,8,9]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3XSQuo4qkIP"
      },
      "source": [
        "Each element along the first axis, is an array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9k5H6uxqkIP",
        "outputId": "37b3c7f2-15d5-4cf4-8cc2-b86b74220b73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL0b6bPmqkIP",
        "outputId": "f27c5b9d-1e7f-41ca-e7b2-276903cdd4d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4, 5, 6]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwOy_5SNqkIP",
        "outputId": "ae20d0f0-e5a3-4ae8-ebde-7fd2f2d3860d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7, 8, 9]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWPvhLi6qkIQ"
      },
      "source": [
        "For this example, Each element along the second axis, is a number:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM2dA3jvqkIS",
        "outputId": "15a0e0d1-67cb-4001-dd12-25daad0b49e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrG3cep_qkIS",
        "outputId": "96733f69-2c64-41db-aa48-bd84b57d886f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvbXIOb9qkIS",
        "outputId": "103cd570-0814-4b76-f21e-dae9b23899e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[2][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL99LRt4qkIT",
        "outputId": "f3d8a423-067a-48b6-a3ca-98aaf4f34d65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dd[2][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLf_DSOkqkIT"
      },
      "source": [
        "##### Note that, with tensors, the elements of the last axis are always numbers. Every other axis will contain n-dimensional arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IU_Q0dvqkIT"
      },
      "source": [
        "### Shape of a tensor\n",
        "The shape of a tensor is determined by the length of each axis, so if we know the shape of a given tensor, then we know the length of each axis, and this tells us how many indexes are available along each axis.\n",
        "\n",
        "##### The shape of a tensor gives us the length of each axis of the tensor.\n",
        "\n",
        "\n",
        "\n",
        "Let's consider the same tensor dd as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpbQIzDeqkIT"
      },
      "outputs": [],
      "source": [
        " dd = [\n",
        "[1,2,3],\n",
        "[4,5,6],\n",
        "[7,8,9]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOC4PqVYqkIU"
      },
      "source": [
        "To work with this tensor's shape, we'll create a torch.Tensor object like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm_ZRLISqkIU",
        "outputId": "c570e22b-0d16-48fe-dd4b-7f21cca9dec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "t = torch.tensor(dd)\n",
        "\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNxm7cl2qkIU",
        "outputId": "50363ff5-c414-4015-aec0-a0afd29d14bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn938rivqkIU"
      },
      "source": [
        "Now, we have a torch.Tensor object, and so we can ask to see the tensor's shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAMhckdGqkIU",
        "outputId": "b2d55262-84dc-426d-ad6f-331c8120be43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wVnqtvqkIV"
      },
      "source": [
        "This allows us to see the tensor's shape is 3 x 3. Note that, in PyTorch, size and shape of a tensor are the same thing.\n",
        "The shape of 3 x 3 tells us that each axis of this rank two tensor has a length of 3 which means that we have three indexes available along each axis.\n",
        "\n",
        "one of the types of operations we must perform frequently when we are programming our neural networks is called reshaping.\n",
        "\n",
        "As our tensors flow through our networks, certain shapes are expected at different points inside the network, and as neural network programmers, it is our job to understand the incoming shape and have the ability to reshape as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asDxmIs5qkIV"
      },
      "source": [
        "Before we look at reshaping tensors, recall how we reshaped the list of terms we started with earlier:\n",
        "\n",
        "* `Shape 6 x 1`\n",
        "\n",
        "   * number\n",
        "   * scalar\n",
        "   * array\n",
        "   * vector\n",
        "   * 2d-array\n",
        "   * matrix\n",
        "   \n",
        "* `Shape 2 x 3`\n",
        "\n",
        "   * number, array, 2d-array\n",
        "   * scalar, vector, matrix\n",
        "*  Shape 3 x 2\n",
        "\n",
        "   * number, scalar\n",
        "   * array, vector\n",
        "   * 2d-array, matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIE-NgTOqkIV"
      },
      "source": [
        "Each of these groups of terms represent the same underlying data only with differing shapes. This is just a little example to motivate the idea of reshaping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svvpR6vMqkIV"
      },
      "source": [
        "Let's look at our example tensor dd again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygc1Y1VCqkIV",
        "outputId": "b0aee0fa-1422-4692-fe92-3dfc4e7df84e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.tensor(dd)\n",
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpHRTMZ5qkIV"
      },
      "source": [
        "This torch.Tensor is a rank 2 tensor with a shape of [3,3] or 3 x 3.\n",
        "Now, suppose we need to reshape t to be of shape [1,9]. This would give us one array along the first axis and nine numbers along the second axis:\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvhFVDrYqkIW",
        "outputId": "6770aa2d-8a89-4a99-84cf-a3282ef38ad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#in order to reshape run the following command\n",
        "t.reshape(1,9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPO9Ual0qkIW",
        "outputId": "5aea565b-1c3e-4c64-a30d-5bfbc2c2b553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 9])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# in order to check the shape of the reshaped tensor\n",
        "t.reshape(1,9).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14o_hG_7qkIW"
      },
      "source": [
        "### CNN tensor input shape and feature maps\n",
        "\n",
        "In this section, we will look at a practical example that demonstrates the use of the tensor concepts rank, axes, and shape.  \\\n",
        "To do this, we'll consider a tensor input to a convolutional neural network. Without further ado, let's get started.\n",
        "\n",
        "Convolutional neural networks are the go-to networks for image recognition tasks because they are well suited for detecting spacial patterns.\n",
        "\n",
        "Remember that the shape of a tensor encodes all the relevant information about a tensor's axes, rank, and indexes, so we'll consider the shape in our example, and this will enable us to work out the other values. Let's begin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21X41rC-qkIW"
      },
      "source": [
        "### Shape of a CNN input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2_uu5OrqkIW"
      },
      "source": [
        "The shape of a CNN input typically has a length of four. This means that we have a rank-4 tensor with four axes.\n",
        "For images, the raw data comes in the form of pixels that are represented by a number and are laid out using two dimensions, height and width.\n",
        "\n",
        "#### we'll work backwards, considering the axes from right to left. Remember, the last axis, which is where we'll start, is where the actual numbers or data values are located.\n",
        "\n",
        "\n",
        "###### Image height and width\n",
        "\n",
        "To represent two dimensions, we need two axes.\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "The image height and width are represented on the last two axes. Possible values here are 28 x 28.\n",
        "\n",
        "The image height and width might vary depending on the deep learning model we will be using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5UvkBWGqkIX"
      },
      "source": [
        "##### Image color channels\n",
        "The next axis represents the color channels. Typical values here are 3 for RGB images or 1 if we are working with grayscale images. This color channel interpretation only applies to the input tensor.\n",
        "\n",
        "In terms of accessing data at this point, we need three indexes. We choose a color channel, a height, and a width to arrive at a specific pixel value.\n",
        "\n",
        "#####  Image batches\n",
        "\n",
        "This brings us to the first axis of the four which represents the batch size. In neural networks, we usually work with batches of samples opposed to single samples, so the length of this axis tells us how many samples are in our batch.\n",
        "\n",
        "This allows us to see that an entire batch of images is represented using a single rank-4 tensor.\n",
        "\n",
        "Suppose we have the following shape [3, 1, 28, 28] for a given tensor. Using the shape, we can determine that we have a batch of three images.\n",
        "\n",
        "                   ` [Batch, Channels, Height, Width] `\n",
        "\n",
        "Each image has a single color channel, and the image height and width are 28 x 28 respectively\n",
        "\n",
        "This gives us a single rank-4 tensor that will ultimately flow through our convolutional neural network.\n",
        "\n",
        "####  NCHW vs NHWC vs CHWN\n",
        "\n",
        "It's common when reading API documentation and academic papers to see the B replaced by an N. The N standing for number of samples in a batch.\n",
        "\n",
        "Furthermore, another difference we often encounter in the wild is a reordering of the dimensions. Common orderings are as follows:\n",
        "\n",
        "   * NCHW\n",
        "   * NHWC\n",
        "   * CHWN\n",
        "   \n",
        "As we have seen, PyTorch uses NCHW\n",
        "\n",
        "\n",
        "####  Output channels and feature maps\n",
        "\n",
        "Let's look at how the interpretation of the color channel axis changes after the tensor is transformed by a convolutional layer.\n",
        "\n",
        "Suppose we have a tensor that contains data from a single 28 x 28 grayscale image. This gives us the following tensor shape: [1, 1, 28, 28]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VZtZMj0qkIX"
      },
      "source": [
        "# More on tensor\n",
        "\n",
        "PyTorch tensors are the data structures we'll be using when programming neural networks in PyTorch.\n",
        "\n",
        "When programming neural networks, data preprocessing is often one of the first steps in the overall process, and one goal of data preprocessing is to transform the raw input data into tensor form.\n",
        "\n",
        "### Instances of the torch.Tensor class\n",
        "\n",
        "PyTorch tensors are instances of the torch.Tensor Python class. We can create a torch.Tensor object using the class constructor like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM_fXufGqkIX",
        "outputId": "4ae9effc-fdc7-4a4c-cb90-da7a1d2d86b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.Tensor()\n",
        "\n",
        "type(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oAvYc2fqkIX"
      },
      "source": [
        "This creates an empty tensor (tensor with no data), but we'll get to adding data in just a moment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gZ8Da4hqkIX"
      },
      "source": [
        "### Tensor attributes\n",
        "First, let's look at a few tensor attributes. Every torch.Tensor has these attributes:\n",
        "\n",
        "   * torch.dtype\n",
        "   * torch.device\n",
        "   * torch.layout\n",
        "\n",
        "Looking at our Tensor t, we can see the following default attribute values:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "PHrR-d5cqkIX",
        "outputId": "15adf689-5adb-4cd4-8343-39ef95596f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "cpu\n",
            "torch.strided\n"
          ]
        }
      ],
      "source": [
        "print(t.dtype)\n",
        "print(t.device)\n",
        "print(t.layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj0-iMfMqkIY"
      },
      "source": [
        "### Tensors have a torch.dtype\n",
        "\n",
        "The dtype, which is torch.float32 in our case, specifies the type of the data that is contained within the tensor. Tensors contain uniform (of the same type) numerical data with one of these types:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKM28Bj-qkIY"
      },
      "source": [
        "| Data type | dtype |\tCPU tensor | GPU tensor |\n",
        "| --- | --- | --- | ---|\n",
        "| 32-bit floating point |\ttorch.float32 |\ttorch.FloatTensor \t| torch.cuda.FloatTensor|\n",
        "|64-bit floating point |\ttorch.float64 |\ttorch.DoubleTensor |\ttorch.cuda.DoubleTensor|\n",
        "|16-bit floating point |\ttorch.float16 |\ttorch.HalfTensor |\ttorch.cuda.HalfTensor|\n",
        "|8-bit integer (unsigned) |\ttorch.uint8 |\ttorch.ByteTensor |\ttorch.cuda.ByteTensor|\n",
        "|8-bit integer (signed) |\ttorch.int8 |\ttorch.CharTensor |\ttorch.cuda.CharTensor|\n",
        "|16-bit integer (signed) |\ttorch.int16 |\ttorch.ShortTensor |\ttorch.cuda.ShortTensor|\n",
        "|32-bit integer (signed) |\ttorch.int32 |\ttorch.IntTensor |\ttorch.cuda.IntTensor|\n",
        "|64-bit integer (signed) |\ttorch.int64 |\ttorch.LongTensor |\ttorch.cuda.LongTensor|\n",
        "\n",
        "Notice how each type has a CPU and GPU version. One thing to keep in mind about tensor data types is that tensor operations between tensors must happen between tensors with the same type of data. However, this statement only applies to PyTorch versions lower than 1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04HixgybqkIY"
      },
      "source": [
        "### PyTorch Tensor Type Promotion\n",
        "\n",
        "Arithmetic and comparison operations, as of PyTorch version 1.3, can perform mixed-type operations that promote to a common dtype.\n",
        "\n",
        "The example below was not allowed in version 1.2. However, in version 1.3 and above, the same code returns a tensor with dtype=torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGO9OcGIqkIY",
        "outputId": "dae44cd1-2a07-4ad7-a2a0-1c2bf17efa52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#let's add data of different type and store them inside result variable\n",
        "result = torch.tensor([1], dtype=torch.int) + torch.tensor([1],dtype=torch.float32)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMsDPwQBqkIY",
        "outputId": "6e02547c-284c-4d65-e19b-3b15b0d0e1cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# in order to check the data type of the result\n",
        "\n",
        "result.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGsky-DqkIZ"
      },
      "source": [
        "### Tensors have a torch.device\n",
        "The device, cpu in our case, specifies the device (CPU or GPU) where the tensor's data is allocated. This determines where tensor computations for the given tensor will be performed.\n",
        "PyTorch supports the use of multiple devices, and they are specified using an index like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIUpKjG_qkIZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUtOEGxOqkIZ",
        "outputId": "87f3be61-efb8-47ad-ab6a-f2ee82ab94b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GKZYhHQqkIZ"
      },
      "source": [
        " One thing to keep in mind about using multiple devices is that tensor operations between tensors must happen between tensors that exists on the same device.\n",
        "\n",
        " Using multiple devices is typically something we will do as we become more advanced users, so there's no need to worry about that now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6vR1V9qkIZ"
      },
      "source": [
        "### Creating tensors using data\n",
        " These are the primary ways of creating tensor objects (instances of the torch.Tensor class), with data (array-like) in PyTorch:\n",
        "\n",
        "    torch.Tensor(data)\n",
        "    torch.tensor(data)\n",
        "    torch.as_tensor(data)\n",
        "    torch.from_numpy(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWkEorjpqkIZ"
      },
      "source": [
        "##### We'll begin by just creating a tensor with each of the options and see what we get. We'll start by creating some data.\n",
        "We can use a Python list, or sequence, but numpy.ndarrays are going to be the more common option, so we'll go with a numpy.ndarray like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTr0AWd5qkIa",
        "outputId": "26afbf1d-1481-4fb5-ba30-905e88def6c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array([1,2,3])\n",
        "\n",
        "type(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm52SIZyqkIa"
      },
      "source": [
        "This gives us a simple bit of data with a type of numpy.ndarray.\n",
        "\n",
        "Now, let's create our tensors with each of these options 1-4, and have a look at what we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdperj-TqkIa"
      },
      "outputs": [],
      "source": [
        "o1 = torch.Tensor(data)\n",
        "o2 = torch.tensor(data)\n",
        "o3 = torch.as_tensor(data)\n",
        "o4 = torch.from_numpy(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGENjUFaqkIa",
        "outputId": "f9f15a26-22e1-4920-ab30-c0f96acaba7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(o1)\n",
        "print(o2)\n",
        "print(o3)\n",
        "print(o4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mFANpthqkIa"
      },
      "source": [
        "All of the options (o1, o2, o3, o4) appear to have produced the same tensors except for the first one. The first option (o1) has dots after the number indicating that the numbers are floats, while the next three options have a type of int32.\n",
        "\n",
        "We will see later which of these options is best for creating tensors. For now, let's see some of the creation options available for creating tensors from scratch without having any data beforehand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fcb3kV_qkIl"
      },
      "source": [
        "### Creation options without data\n",
        "\n",
        "Here are some other creation options that are available.\n",
        "\n",
        "##### We have the torch.eye() function which returns a 2-D tensor with ones on the diagonal and zeros elsewhere. The name eye() is connected to the idea of an identity matrix , which is a square matrix with ones on the main diagonal and zeros everywhere else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo0F04GoqkIl",
        "outputId": "ee74ddf0-f4d2-4c72-e5d9-93c4ae56aee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0.],\n",
            "        [0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.eye(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNBv-QAkqkIl"
      },
      "source": [
        "###### We have the torch.zeros() function that creates a tensor of zeros with the shape of specified shape argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVAm4kzCqkIl",
        "outputId": "6963c873-e9f3-47f3-ba88-880f982bfec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.zeros([2,2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bZWPvweqkIm"
      },
      "source": [
        "##### Similarly, we have the torch.ones() function that creates a tensor of ones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv3mIot2qkIm",
        "outputId": "bb8e0fe1-47a9-4e82-ae25-3da890cd0884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.ones([2,2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryX3u58TqkIm"
      },
      "source": [
        "##### We also have the torch.rand() function that creates a tensor with a shape of the specified argument whose values are random."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKdjkOWmqkIm",
        "outputId": "9ddd58a4-df45-41a1-cc59-fe7a47e3deab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8158, 0.9623],\n",
            "        [0.7792, 0.3234]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.rand([2,2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Yv9fZNqkIm"
      },
      "source": [
        " ### Creating PyTorch Tensors - Best Options\n",
        "In this section, we'll know the differences between the primary options as well as which options should be used and when.\n",
        "\n",
        "As we have seen before we have multiple options to create tensor. Among them torch.Tensor() constructor uses the default dtype when building the tensor. We can verify the default dtype using the torch.get_default_dtype() method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URpm2BsuqkIn",
        "outputId": "94aa74f6-8c20-4a08-bc61-9120f200c426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.get_default_dtype()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUoLi6-IqkIn"
      },
      "source": [
        "The other calls choose a dtype based on the incoming data. This is called type inference. The dtype is inferred based on the incoming data. Note that the dtype can also be explicitly set for these calls by specifying the dtype as an argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fed00u6_qkIn",
        "outputId": "5f12b6d2-6c65-470d-9aab-734392ddbb83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(data, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhGH5g_dqkIn",
        "outputId": "a2e78f5c-b65e-4ac3-fe62-d3e29a3ff9bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(data, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5NOOndGqkIn"
      },
      "source": [
        "With torch.Tensor(), we are unable to pass a dtype to the constructor. This is an example of the torch.Tensor() constructor lacking in configuration options. This is one of the reasons to go with the torch.tensor() factory function for creating our tensors.\n",
        "\n",
        "Let's look at the last hidden difference between these alternative creation methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_G9EIvjqkIn"
      },
      "source": [
        "### Sharing memory for performance: copy vs share"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjGeNpSVqkIo"
      },
      "source": [
        "The third difference is lurking behind the scenes or underneath the hood. To reveal the difference, we need to make a change to the original input data in the numpy.ndarray after using the ndarray to create our tensors.\n",
        "\n",
        "Let's do this and see what we get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3i6TRheqkIo",
        "outputId": "ff5272d4-6667-4ecf-8abe-a3171a8262a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "old: [1 2 3]\n"
          ]
        }
      ],
      "source": [
        "print('old:', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCEMImgyqkIo"
      },
      "outputs": [],
      "source": [
        "#change the value of index 0 from the main array\n",
        "data[0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3AABW_6qkIo",
        "outputId": "bb03020b-3e2f-474d-97bd-4b8cb76161fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new: [0 2 3]\n"
          ]
        }
      ],
      "source": [
        "#now lets print the array\n",
        "print('new:', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAf_K3vLqkIo",
        "outputId": "53438d02-b3bf-4e0a-d2fa-7449cb24a196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3])\n",
            "tensor([0, 2, 3])\n",
            "tensor([0, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(o1)\n",
        "\n",
        "print(o2)\n",
        "\n",
        "print(o3)\n",
        "\n",
        "print(o4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGpq5OrFqkIo"
      },
      "source": [
        "Note that originally, we had **data[0]=1**, and also note that we only changed the data in the original numpy.ndarray. Notice we didn't explicity make any changes to our tensors **(o1, o2, o3, o4)**.\n",
        "\n",
        "However, after setting **data[0]=0**, we can see some of our tensors have changes. The first two o1 and o2 still have the original value of 1 for index 0, while the second two o3 and o4 have the new value of 0 for index 0.\n",
        "\n",
        "This happens because **torch.Tensor()** and **torch.tensor()** copy their input data while **torch.as_tensor()** and **torch.from_numpy()** share their input data in memory with the original input object.\n",
        "\n",
        "| Share Data |\tCopy Data |\n",
        "| --- | --- |\n",
        "|torch.as_tensor()  |\ttorch.tensor() |\n",
        "|torch.from_numpy()  |\ttorch.Tensor()  |\n",
        "\n",
        "This sharing just means that the actual data in memory exists in a single place. As a result, any changes that occur in the underlying data will be reflected in both objects, the torch.Tensor and the numpy.ndarray."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idfgnKEpqkIp"
      },
      "source": [
        "##### If we have a torch.Tensor and we want to convert it to a numpy.ndarray, we do it like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLnc1Jg4qkIp",
        "outputId": "c73e59e1-51ad-4e0e-a9ab-5c078d8cbb82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 2 3]\n",
            "[0 2 3]\n"
          ]
        }
      ],
      "source": [
        "print(o3.numpy())\n",
        "print(o4.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1gqnCYaqkIp"
      },
      "source": [
        "This gives:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKoTNTkmqkIp",
        "outputId": "bbf05b95-338d-401e-c9d3-45e02aea22c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(o3.numpy()))\n",
        "print(type(o4.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJPudHbeqkIp"
      },
      "source": [
        "### Best options for creating tensors in PyTorch\n",
        "\n",
        "Given all of these details, these two are the best options:\n",
        "\n",
        "  *  torch.tensor()\n",
        "  * torch.as_tensor()\n",
        "\n",
        "The torch.tensor() call is the sort of go-to call, while torch.as_tensor() should be employed when tuning our code for performance.\n",
        "\n",
        "##### Some things to keep in mind about memory sharing (it works where it can):\n",
        "\n",
        "   1. Since numpy.ndarray objects are allocated on the CPU, the as_tensor() function must copy the data from the CPU to the GPU when a GPU is being used.\n",
        "   2. The memory sharing of as_tensor() doesn't work with built-in Python data structures like lists.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atg19FbRqkIp"
      },
      "source": [
        "# Reshaping Operations - Tensors For Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpdVQ8HYqkIp"
      },
      "source": [
        "## Tensor Operation Types\n",
        "\n",
        "Before we dive in with specific tensor operations, let's get a quick overview of the landscape by looking at the main operation categories that encompass the operations we'll cover. We have the following high-level categories of operations:\n",
        "1. Reshaping operations\n",
        "2. Element-wise operations\n",
        "3. Reduction operations\n",
        "4. Access operations\n",
        "\n",
        "## Reshaping Operations For Tensors\n",
        "\n",
        "Tensor Shape Review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbeXTx8vqkIp"
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([\n",
        "    [1,1,1,1],\n",
        "    [2,2,2,2],\n",
        "    [3,3,3,3]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRzXeXAbqkIr"
      },
      "source": [
        "To determine the shape of this tensor, we look first at the rows 3 and then the columns 4, and so this tensor is a 3 x 4 rank 2 tensor. Remember, rank is a word that is commonly used and just means the number of dimensions present within the tensor.\n",
        "\n",
        "In PyTorch, we have two ways to get the shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbruzHA2qkIr",
        "outputId": "1e00d710-fae9-4c59-e9fc-65a38a3193e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB778bucqkIs",
        "outputId": "bdc23a3d-bea6-4e13-d920-9ace35e985ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fntoW6-qkIs"
      },
      "source": [
        "In PyTorch the size and shape of a tensor mean the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-ULMyy9qkIs"
      },
      "source": [
        "Typically, after we know a tensor's shape, we can deduce a couple of things. First, we can deduce the tensor's rank. The rank of a tensor is equal to the length of the tensor's shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEE5VqxBqkIs",
        "outputId": "a5395d27-3224-421d-f6a8-9a1ed52c2e32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj71pBGjqkIs"
      },
      "source": [
        "We can also deduce the number of elements contained within the tensor. The number of elements inside a tensor (12 in our case) is equal to the product of the shape's component values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t16em5O5qkIt",
        "outputId": "0cfea672-7f96-4b59-9557-5bfa79b6ef13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(12)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(t.shape).prod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMzUCaqYqkIt"
      },
      "source": [
        "In PyTorch, there is a dedicated function for this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVDVevSoqkIt",
        "outputId": "f1597285-a56c-4f3d-f7ce-95d4b61a6a14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.numel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8VzC3SoqkIt"
      },
      "source": [
        "The number of elements contained within a tensor is important for reshaping because the reshaping must account for the total number of elements present. Reshaping changes the tensor's shape but not the underlying data. Our tensor has 12 elements, so any reshaping must account for exactly 12 elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1UzHji_qkIt"
      },
      "source": [
        "# Reshaping A Tensor In PyTorch\n",
        "Let's look now at all the ways in which this tensor t can be reshaped without changing the rank:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v88VjFh3qkIt",
        "outputId": "0366dea7-8dac-4058-f911-094cf338e75a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape([1,12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTinTQGqqkIt",
        "outputId": "ea051917-3503-469c-8bc2-3548ede978b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 2., 2.],\n",
              "        [2., 2., 3., 3., 3., 3.]])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape([2,6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5opexf1wqkIu",
        "outputId": "82a53dd2-8b32-4ecb-a3a3-55fd2a50f877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.]])"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape([3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gVjVqd1qkIu",
        "outputId": "efb8cfa7-9433-4a02-eac1-38670e50568f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 2., 2.],\n",
              "        [2., 2., 3.],\n",
              "        [3., 3., 3.]])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape([4,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgGsBIYtqkIu",
        "outputId": "92e38c55-f28c-477f-b615-2d3e8cfbbdb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape(6,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaNXOxWrqkIu",
        "outputId": "e562ba0f-7adc-41e2-e70e-d68bb3e91b49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [3.]])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape(12,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq3a7eMOqkIu"
      },
      "source": [
        "Using the reshape() function, we can specify the row x column shape that we are seeking. Notice how all of the shapes have to account for the number of elements in the tensor. In our example this is:\n",
        "\n",
        "**rows * columns = 12 elements**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfZr5x6mqkIv"
      },
      "source": [
        "We can use the intuitive words rows and columns when we are dealing with a rank 2 tensor. The underlying logic is the same for higher dimensional tenors even though **we may not be able to use the intuition of rows and columns in higher dimensional spaces**. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpQWebMfqkIv",
        "outputId": "bf85f237-7710-4196-da92-8389739197e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.],\n",
              "         [1., 2., 2.]],\n",
              "\n",
              "        [[2., 2., 3.],\n",
              "         [3., 3., 3.]]])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.reshape(2,2,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MRLKHCbqkIv"
      },
      "source": [
        "In this example, we increase the rank to 3, and so we lose the rows and columns concept. However, the product of the shape's components (2,2,3) still has to be equal to the number of elements in the original tensor ( 12).\n",
        "\n",
        "Note that PyTorch has another function that you may see called view() that does the same thing as the reshape() function, but don't let these names throw you off. No matter which deep learning framework we are using, these concepts will be the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7yjhcznqkIv"
      },
      "source": [
        "# Changing Shape By Squeezing And Unsqueezing\n",
        "\n",
        "The next way we can change the shape of our tensors is by squeezing and unsqueezing them.\n",
        "\n",
        "Squeezing a tensor removes the dimensions or axes that have a length of one.\n",
        "Unsqueezing a tensor adds a dimension with a length of one.\n",
        "\n",
        "These functions allow us to expand or shrink the rank (number of dimensions) of our tensor. Let's see this in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcUM_eCWqkIv",
        "outputId": "783c8e5c-8507-4198-88c3-c58e82cf4fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "print(t.reshape([1,12]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGTcqGfXqkIv",
        "outputId": "382166cc-0967-4818-bc2f-0d8ba7e8c887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ]
        }
      ],
      "source": [
        "print(t.reshape([1,12]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h19ufy_wqkIv",
        "outputId": "fa71f451-2939-4ebe-8109-6e82335b928c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n"
          ]
        }
      ],
      "source": [
        "print(t.reshape([1,12]).squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uomAj6mqkIw",
        "outputId": "571dca67-eced-4dce-d397-ed63cff39723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12])\n"
          ]
        }
      ],
      "source": [
        "print(t.reshape([1,12]).squeeze().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RZ-Jj6JqkIw",
        "outputId": "d09dd9f1-b606-440a-b686-b18d775c50ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "print(t.reshape([1,12]).squeeze().unsqueeze(dim=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ERN-4bGqkIw",
        "outputId": "dfbf1d3f-f9b6-4643-84c2-2ebf187e32e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ]
        }
      ],
      "source": [
        "print(t.reshape([1,12]).squeeze().unsqueeze(dim=0).shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Haag0aqkIw"
      },
      "source": [
        "# In order to flatten a tensor we call flatten() method and pass the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5k4ei7sqkIw"
      },
      "outputs": [],
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhHNyq43qkIw",
        "outputId": "ba6e4331-306c-4b8d-a16f-0936c5909ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.flatten(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHe3JAGOqkIw"
      },
      "source": [
        "# Concatenating Tensors\n",
        "\n",
        "We combine tensors using the cat() function, and the resulting tensor will have a shape that depends on the shape of the two input tensors.\n",
        "\n",
        "Suppose we have two tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUjUeXQOqkIw"
      },
      "outputs": [],
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "])\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [5,6],\n",
        "    [7,8]\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbVNmA7lqkIx"
      },
      "source": [
        "We can combine t1 and t2 row-wise (axis-0) in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpgreQ3HqkIx",
        "outputId": "f98a9af5-cc7b-4a63-f829-1fea61bff732"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6],\n",
              "        [7, 8]])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat((t1, t2), dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaPd0L9-qkIx"
      },
      "source": [
        "We can combine them column-wise (axis-1) like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gffEAhaxqkIx",
        "outputId": "3c073e92-f208-49cf-bbbc-58857b531be0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 5, 6],\n",
              "        [3, 4, 7, 8]])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat((t1, t2), dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIplVYRGqkIx"
      },
      "source": [
        "When we concatenate tensors, we increase the number of elements contained within the resulting tensor. This causes the component values within the shape (lengths of the axes) to adjust to account for the additional elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKGtZHVMqkIx",
        "outputId": "384c3625-1e99-4d1e-fdd3-9785d17d16b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 2])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat((t1, t2), dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek8VNhzHqkIx",
        "outputId": "1fb3b7e9-4174-4f18-8045-3ee5ee06ab69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat((t1, t2), dim=1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YepffmRQqkIy"
      },
      "source": [
        "# Element-wise operations\n",
        "\n",
        "An element-wise operation operates on corresponding elements between tensors.\n",
        "\n",
        "Two elements are said to be corresponding if the two elements occupy the same position within the tensor. The position is determined by the indexes used to locate each element.\n",
        "\n",
        "Suppose we have the following two tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af7FVszNqkIy"
      },
      "outputs": [],
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK0BEZl2qkIy"
      },
      "outputs": [],
      "source": [
        "t2 = torch.tensor([\n",
        "    [9,8],\n",
        "    [7,6]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXgzzjugqkIy"
      },
      "source": [
        "Both of these tensors are rank-2 tensors with a shape of 2 x 2.\n",
        "\n",
        "This means that we have two axes that both have a length of two elements each. The elements of the first axis are arrays and the elements of the second axis are numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QenQ3TzYqkIy"
      },
      "source": [
        "## Addition Is An Element-Wise Operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q91x_11uqkIy",
        "outputId": "8f14ab84-e7f5-409a-809e-f58e5b24866a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[10., 10.],\n",
              "        [10., 10.]])"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 + t2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2gJA2XbqkIz"
      },
      "source": [
        "This allow us to see that addition between tensors is an element-wise operation. Each pair of elements in corresponding locations are added together to produce a new tensor of the same shape.\n",
        "\n",
        "So, addition is an element-wise operation, and in fact, all the arithmetic operations, add, subtract, multiply, and divide are element-wise operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6OyywbGqkIz"
      },
      "source": [
        "# Arithmetic Operations Are Element-Wise Operations\n",
        "An operation we commonly see with tensors are arithmetic operations using scalar values. There are two ways we can do this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzOxH9aQqkIz",
        "outputId": "676617ef-7501-4814-f132-7eb4dea824a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n"
          ]
        }
      ],
      "source": [
        "print(t1 + 2)\n",
        "print(t1.add(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIaJwUr4qkIz",
        "outputId": "1a34154a-d805-4ddb-fcd5-e55d948ed683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n",
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n"
          ]
        }
      ],
      "source": [
        "print(t1 - 2)\n",
        "print(t1.sub(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuplcZP7qkIz",
        "outputId": "339ccdd7-ba6c-4e33-b7a9-8ff3bfa2c83b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n"
          ]
        }
      ],
      "source": [
        "print(t1 * 2)\n",
        "print(t1.mul(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uAUNUSaqkIz",
        "outputId": "ec56aa11-4c17-4fdd-dde0-d75918c391e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n",
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ]
        }
      ],
      "source": [
        "print(t1 / 2)\n",
        "print(t1.div(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoE5AIZYqkI0"
      },
      "source": [
        "#### Both of these options work the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxdm-9FJqkI0"
      },
      "source": [
        "## So how does this fit in? Let's break it down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlOHSARXqkI0"
      },
      "source": [
        "# Broadcasting Tensors\n",
        "\n",
        "Broadcasting is the concept whose implementation allows us to add scalars to higher dimensional tensors.\n",
        "\n",
        "We can see what the broadcasted scalar value looks like using the broadcast_to() Numpy function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY5xaBTTqkI0",
        "outputId": "fbe42a7a-71cb-48b8-8e19-9ff8cff219d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 2],\n",
              "       [2, 2]])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.broadcast_to(2, t1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOSNcXivqkI0"
      },
      "source": [
        "This means the scalar value is transformed into a rank-2 tensor just like t1, and just like that, the shapes match and the element-wise rule of having the same shape is back in play. This is all under the hood of course.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPrEQSnlqkI0",
        "outputId": "ce0889f8-8133-470f-fc58-bb6ec63eeeaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 + 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uj8VzNMqkI0"
      },
      "source": [
        "is really this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpqRv80VqkI0",
        "outputId": "7a779003-e805-404a-ff34-69e33ec34167"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 + torch.tensor(\n",
        "    np.broadcast_to(2, t1.shape)\n",
        "    ,dtype=torch.float32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCgwIWO-qkI1"
      },
      "source": [
        "### Comparison Operations Are Element-Wise:\n",
        "\n",
        "For a given comparison operation between two tensors, a new tensor of the same shape is returned with each element containing either a torch.bool value of True or False.\n",
        "\n",
        "### Element-Wise Comparison Operation Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxlDJKR2qkI1"
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([\n",
        "    [0,5,0],\n",
        "    [6,0,7],\n",
        "    [0,8,0]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf1zvKlQqkI1",
        "outputId": "bd269625-f455-426c-e77b-9c255f6c29bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ True, False,  True],\n",
              "        [False,  True, False],\n",
              "        [ True, False,  True]])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.eq(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF_yO-ZYqkI1",
        "outputId": "9e2b049f-a436-427d-891b-1863a97f06cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.ge(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxXInBEeqkI1",
        "outputId": "48c1904a-e0c2-47ca-8e06-398b6881dd81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False,  True, False],\n",
              "        [ True, False,  True],\n",
              "        [False,  True, False]])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.gt(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-PqyA2CqkI1",
        "outputId": "9f276a9b-1d86-4efa-c7ab-785537b8391b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False]])"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.lt(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3VCwoqFqkI1",
        "outputId": "568f38f8-7999-4b96-ead6-ac846f07edf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True, False,  True]])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.le(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_OG9e3JqkI1"
      },
      "source": [
        "### Element-Wise Operations Using Functions\n",
        "With element-wise operations that are functions, it's fine to assume that the function is applied to each element of the tensor.\n",
        "\n",
        "Here are some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEBY1ad6qkI1",
        "outputId": "0463bc3d-a2bb-484b-a6b2-cb59489a6df2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 5., 0.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.abs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88osB3M4qkI2",
        "outputId": "9364b4dc-24b6-46d7-8ca3-493be748c002"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 2.2361, 0.0000],\n",
              "        [2.4495, 0.0000, 2.6458],\n",
              "        [0.0000, 2.8284, 0.0000]])"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.sqrt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw70an60qkI2",
        "outputId": "f12b9e4e-abb4-4c02-ea3a-53812c886e4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0., -5., -0.],\n",
              "        [-6., -0., -7.],\n",
              "        [-0., -8., -0.]])"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.neg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpx7h31kqkI2",
        "outputId": "a3fe5372-0930-42ad-87c6-00a64f078477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 5., 0.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.neg().abs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhbU6sKsqkI2"
      },
      "source": [
        "### Some Terminology\n",
        "There are some other ways to refer to element-wise operations, so I just wanted to mention that all of these mean the same thing:\n",
        "\n",
        "* Element-wise\n",
        "* Component-wise\n",
        "* Point-wise\n",
        "\n",
        "Just keep this in mind if you encounter any of these terms in the wild."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFb1lDbSqkI2"
      },
      "source": [
        "### Tensor Reduction Operations\n",
        "\n",
        "A reduction operation on a tensor is an operation that reduces the number of elements contained within the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWWgRJcmqkI3"
      },
      "source": [
        "### Reduction Operation Example\n",
        "Suppose we the following 3 x 3 rank-2 tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNdIPrDjqkI3"
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([\n",
        "    [0,1,0],\n",
        "    [2,0,2],\n",
        "    [0,3,0]\n",
        "], dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlPCsbOjqkI3",
        "outputId": "fd3a4506-d3f9-4a3d-db74-21869ad680e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4_smnQmqkI3",
        "outputId": "ae43b676-9cc6-4c95-ecae-77b11d518746"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IorBimpaqkI3",
        "outputId": "a58a3258-aac6-4047-c114-b35b95dfbc97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.sum().numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptjdXFZsqkI3",
        "outputId": "2b185031-5d7e-41a6-b0d2-859eb5df3e8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.sum().numel() < t.numel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSICm4tdqkI3"
      },
      "source": [
        "### Common Tensor Reduction Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pu_cfcsqkI4",
        "outputId": "e4b71883-a048-4791-d644-66de0294f8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.)\n",
            "tensor(0.)\n",
            "tensor(0.8889)\n"
          ]
        }
      ],
      "source": [
        "print(t.sum())\n",
        "\n",
        "print(t.prod())\n",
        "\n",
        "print(t.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0AjSb2nqkI4"
      },
      "source": [
        "All of these tensor methods reduce the tensor to a single element scalar valued tensor by operating on all the tensor's elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slI9xbvfqkI4"
      },
      "source": [
        "## Do reduction operations always reduce to a tensor with a single element?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev2VdP7UqkI4"
      },
      "source": [
        "### Reducing Tensors By Axes\n",
        "To reduce a tensor with respect to a specific axis, we use the same methods, and we just pass a value for the dimension parameter. Let's see this in action.\n",
        "\n",
        "Suppose we have the following tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwlFQYAxqkI4"
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([\n",
        "    [1,1,1,1],\n",
        "    [2,2,2,2],\n",
        "    [3,3,3,3]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WonT7EibqkI4"
      },
      "source": [
        "This is a 3 x 4 rank-2 tensor. Having different lengths for the two axes will help us understand these reduce operations.\n",
        "\n",
        "Let's consider the sum() method again. Only, this time, we will specify a dimension to reduce. We have two axes so we'll do both. Check it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX5fcC_jqkI4",
        "outputId": "a67635c8-04c4-454c-99ee-b0aa4bbde400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6., 6., 6., 6.])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.sum(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klyUFp5cqkI4"
      },
      "source": [
        "When I first saw this when I was learning how this works, I was confused. If you're confused like I was, I highly recommend you try to understand what's happening here before going forward.\n",
        "\n",
        "Remember, we are reducing this tensor across the first axis, and elements running along the first axis are arrays, and the elements running along the second axis are numbers.\n",
        "\n",
        "Let's go over what happened here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTl9UFKgqkI4"
      },
      "source": [
        "### Understanding Reductions By Axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeAw58BLqkI5",
        "outputId": "a58313c7-3b4f-4726-eec3-4dfd3ccf5486"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_fKOXesqkI5",
        "outputId": "e594aa97-3f39-4ef1-dd5b-ec588ac3210e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2.])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnJQPiOuqkI5",
        "outputId": "b0066217-d0a9-49e9-f377-9dd68ee04fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 3., 3., 3.])"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r824QabCqkI5",
        "outputId": "ab41e881-ab46-4067-8b7b-90c48412b6cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6., 6., 6., 6.])"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[0] + t[1] + t[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJaV4ay7qkI5"
      },
      "source": [
        "###  Element-wise operations are in play here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOxiLqx8qkI5"
      },
      "source": [
        "When we sum across the first axis, we are taking the summation of all the elements of the first axis. To do this, we must utilize element-wise addition.\n",
        "\n",
        "The second axis in this tensor contains numbers that come in groups of four. Since we have three groups of four numbers, we get three sums."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFGr4hZmqkI5",
        "outputId": "72f5ac62-a927-454d-edcf-cd1f4ffae375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[0].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIz50hT9qkI5",
        "outputId": "9ecc35f5-3681-4f4b-a94a-0a7faa879a7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[1].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMgnf4PkqkI5",
        "outputId": "4f7c7ac7-1486-4407-ad9e-ca199b08afb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(12.)"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[2].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBZ_5FKqqkI6",
        "outputId": "3724d615-9eed-4b9c-bcb3-362be96af30a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 4.,  8., 12.])"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.sum(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H84mIjPNqkI6"
      },
      "source": [
        "# Argmax Tensor Reduction Operation\n",
        "\n",
        "Argmax returns the index location of the maximum value inside a tensor.\n",
        "\n",
        "When we call the argmax() method on a tensor, the tensor is reduced to a new tensor that contains an index value indicating where the max value is inside the tensor. Let's see this in code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID4u7U6KqkI6"
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([\n",
        "    [1,0,0,2],\n",
        "    [0,3,3,0],\n",
        "    [4,0,0,5]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRpLhdyXqkI6"
      },
      "source": [
        "In this tensor, we can see that the max value is the 5 in the last position of the last array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HiIskFKqkI6",
        "outputId": "6a03e273-a09f-48d5-afad-e64e31e664e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkXNaOmbqkI6"
      },
      "source": [
        "### Argmax() returns us the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "junqZelEqkI6",
        "outputId": "3be8603a-afd2-4d11-cd26-fd311d308db6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(11)"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJiSiHitqkI6"
      },
      "source": [
        "The first piece of code confirms for us that the max is indeed 5, but the call to the argmax() method tells us that the 5 is sitting at index 11. What's happening here?\n",
        "\n",
        "We'll have a look at the flattened output for this tensor. If we don't specific an axis to the argmax() method, it returns the index location of the max value from the flattened tensor, which in this case is indeed 11.\n",
        "\n",
        "Let's see how we can work with specific axes now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGHB4tRAqkI7",
        "outputId": "2aea39e1-b6d0-406f-fa1a-727d838f9d5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([4., 3., 3., 5.]),\n",
              "indices=tensor([2, 1, 1, 2]))"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.max(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVYnIYXsqkI7",
        "outputId": "31a35b26-45c0-43cf-c053-e29ee9ac322b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([2., 3., 5.]),\n",
              "indices=tensor([3, 1, 3]))"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.max(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjg41sLBqkI7",
        "outputId": "24785e0a-b874-4e21-eb6d-a928c2dc391e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 1, 3])"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxGosjcqkI7"
      },
      "source": [
        "### Accessing Elements Inside Tensors\n",
        "\n",
        "The last type of common operation that we need for tensors is the ability to access data from within the tensor. Let's look at these for PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh26SjGxqkI7"
      },
      "outputs": [],
      "source": [
        "t = torch.tensor([\n",
        "    [1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9]\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2rCqio3qkI7",
        "outputId": "648452ae-d508-4b99-cfc4-0f138929cf7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SoQXWXHqkI7",
        "outputId": "705b2a21-bcd2-41d5-8d21-b5c8d80cfda0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.mean().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QscrTKgCqkI8"
      },
      "source": [
        "Check out these operations on this one. When we call mean on this 3 x 3 tensor, the reduced output is a scalar valued tensor. If we want to actually get the value as a number, we use the item() tensor method. This works for scalar valued tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOCjkviLqkI8"
      },
      "source": [
        "### Have a look at how we do it with multiple values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p39iAMPcqkI8",
        "outputId": "e749b066-faae-4d71-cb1b-c1a1f01f6bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4.0, 5.0, 6.0]"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.mean(dim=0).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S72oVsObqkI8",
        "outputId": "b0bb254b-1eee-4d4f-f62c-8b4ad429b6d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4., 5., 6.], dtype=float32)"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.mean(dim=0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICgD5BVRqkI8"
      },
      "source": [
        "When we compute the mean across the first axis, multiple values are returned, and we can access the numeric values by transforming the output tensor into a Python list or a NumPy array."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "senti",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}