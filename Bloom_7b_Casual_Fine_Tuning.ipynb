{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akib1162100/ML_base/blob/main/Bloom_7b_Casual_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNcUJ2BU6biu",
        "outputId": "433fa127-e04a-4e15-c6fa-48954a69deb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin c:\\users\\acer\\downloads\\llama or bloom\\bloom\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "from transformers import BloomModel, BloomTokenizerFast, BloomForCausalLM, BloomConfig, TextDataset, TrainingArguments, Trainer, pipeline, DataCollatorForLanguageModeling\n",
        "warnings.filterwarnings('ignore')\n",
        "import transformers, accelerate, peft\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46nYNEpD6biz",
        "outputId": "f3d17992-c67e-4c2c-9e24-73197ffd531d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers version: 4.31.0\n",
            "Accelerate version: 0.21.0\n",
            "PEFT version: 0.4.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"Accelerate version: {accelerate.__version__}\")\n",
        "print(f\"PEFT version: {peft.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6-XC53E6biz",
        "outputId": "686b66fb-cda1-447d-e2b1-1d4ff91347e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset text (C:/Users/ACER/.cache/huggingface/datasets/text/default-da1166b43c04c884/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"text\", data_files = \"test3.txt\", split = 'train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dswqIc126bi0",
        "outputId": "a9cdab6d-4a77-4cb1-c5f3-d3b3ee7b769e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 39\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH0u9Uah6bi0",
        "outputId": "3e128af8-1bb5-444f-f244-72e935c9501c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"আমার ওপর ভরসা রাখুন, আমি জেমস বন্ডকে এত সহজে এই ছবিতে উতরে যেতে দেব না।'\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['text'][5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOe-S7oq6bi1",
        "outputId": "41df471d-14aa-4789-b11c-f2de0b66b06e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at C:\\Users\\ACER\\.cache\\huggingface\\datasets\\text\\default-da1166b43c04c884\\0.0.0\\cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2\\cache-96c8a216dc97cf17.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.shuffle(seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHUg5I_y6bi1",
        "outputId": "f5a126d8-bb97-4f06-fd4f-0be6de0624d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"আন্তর্জাতিক দলও এ বিষয়টি নিশ্চিত করেছে।'\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['text'][5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8LUkUoo6bi1",
        "outputId": "c71baf5d-3c1e-49c3-cbc5-ccf109d4df6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_Xnp0Jb6bi2"
      },
      "outputs": [],
      "source": [
        "# news= open('en_US/en_US.news.txt',encoding=\"utf8\").read()\n",
        "# # blogs= open('en_US/en_US.blogs.txt',encoding=\"utf8\").read()\n",
        "# # twitter= open('en_US/en_US.twitter.txt',encoding=\"utf8\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "T_eXf7EX6bi2"
      },
      "outputs": [],
      "source": [
        "def extra_space(text):\n",
        "    new_text= re.sub(\"\\s+\",\" \",text)\n",
        "    return new_text\n",
        "def sp_charac(text):\n",
        "    new_text=re.sub(\"[^0-9A-Za-z ]\", \"\" , text)\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad08h6jM6bi2"
      },
      "source": [
        "### Removing extra space and special characters to find the average word count in each sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXJGO8ms6bi4",
        "outputId": "62223a89-a175-427c-a3fe-195bc5f326fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"অরুণাচলের কংগ্রেস দলীয় এমপি নিনং ইরিং মোদিকে পাঠানো চিঠিতে লিখেছেন, 'প্রমত্তা সিয়াং (ব্রহ্মপুত্র নদের আঞ্চলিক নাম) নদীর পানি এই নভেম্বর মাসে নোংরা ও কালো হওয়ার অন্য কোনো কারণ নেই।\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J3XAps36bi4"
      },
      "outputs": [],
      "source": [
        "for i in range(len(dataset['text'])) :\n",
        "    dataset['text'][i] = extra_space(dataset['text'][i])\n",
        "    # text_corpus[i] = sp_charac(text_corpus[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJIGAghs6bi5",
        "outputId": "390a7337-3d37-40bc-f71f-9f496be53c5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42awYRDb6bi5",
        "outputId": "a855fedb-2e52-4d73-81e2-a5af2441761a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 39\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gDoTxv36bi5"
      },
      "source": [
        "### Dividing the sentences in train and test data and saving it in file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5lh-epR6bi6"
      },
      "outputs": [],
      "source": [
        "dev = dataset.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tldyC5gJ6bi6",
        "outputId": "80a54e9b-b40c-425b-fb91-44f5c7f24cfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"বন্ড সিরিজের নতুন পরিচালক ফুকুনাগা এর আগে এইচবিও চ্যানেলের জনপ্রিয় আমেরিকান টিভি সিরিজ 'ট্রু ডিটেকটিভ'-এর পরিচালক হিসেবে খ্যাতি অর্জন করেছেন।\",\n",
              " \"তখন ভয়ংকর নতুন প্রযুক্তি নিয়ে সদলবলে হাজির হবে এক রহস্যময় ভিলেন।'\",\n",
              " 'ব্রহ্মপুত্রের গতিপথ বদলাতে সুড়ঙ্গ নির্মাণ করছে চীন',\n",
              " 'কিন্তু আমি শিগগিরই নতুন বন্ড সিরিজের শিল্পী আর কলাকুশলীদের সঙ্গে যোগ দেব।',\n",
              " 'কোচিং সেন্টারে ওই হামলায় আফগান কর্তৃপক্ষ বৃহস্পতিবার ৩৪ জন নিহত এবং ৫৬ জন আহত হওয়ার কথা জানায়।',\n",
              " \"সবকিছু ঠিক থাকলে ২০২০ সালের এপ্রিলে মুক্তি পাবে 'বন্ড টুয়েন্টি ফাইভ'। ডেকান ক্রনিকল\",\n",
              " \"নিনং ইরিং আরো লিখেছেন, 'অতীতে কখনো নদের পানির মান এতো খারাপ হওয়ার তথ্য স্থানীয় লোকজনেরও জানা নেই।\",\n",
              " 'তবে এর সপক্ষে তারা কোনো প্রমাণ দেয়নি।',\n",
              " \"আফগান কোচিং সেন্টারে হামলার দায় স্বীকার আইএস'র\",\n",
              " 'বন্ড জ্যামাইকাতে অবকাশ কাটাচ্ছে।',\n",
              " 'এটি বিশ্বে কৃত্রিমভাবে নদীর গতিপ্রবাহ পরিবর্তনের সবচেয়ে বড় পরিকল্পনা।',\n",
              " 'এমন সময় সিআইএর পুরোনো বন্ধু ফেলিক্স লেইটার তাঁর কাছে সাহায্য চান।',\n",
              " \"বন্ড সিরিজের নতুন ছবিতে দর্শক এমন কিছু আশা করে, যা তারা আগে দেখেনি।'\",\n",
              " 'প্রথমে ৪৮ জন নিহত হওয়ার কথা বলা হলেও পরে তা সংশোধন করে ৩৪ জনে নামিয়ে আনা হয়েছে এবং আহতের সংখ্যাও সংশোধন করা হয়েছে বলে জানান স্বাস্থ্য মন্ত্রণালয়ের কর্মকর্তারা।',\n",
              " 'পুলিশ জানায়, পশ্চিম কাবুলের শিয়া হাজারা সম্প্রদায় অধ্যুষিত এলাকার ওই কোচিং সেন্টারটিতে নিয়মিত ক্লাস চলার সময়ে এক আত্মঘাতী বোমা হামলাকারী হেঁটে সেখানে প্রবেশ করে এবং শরীরে বাঁধা বিস্ফোরক বেল্টের বিস্ফোরণ ঘটায়।',\n",
              " \"আমার ওপর ভরসা রাখুন, আমি জেমস বন্ডকে এত সহজে এই ছবিতে উতরে যেতে দেব না।'\",\n",
              " 'আফগানিস্তানের রাজধানী কাবুলে একটি কোচিং সেন্টারে বুধবারের আত্মঘাতী বোমা হামলার দায় স্বীকার করেছে ইসলামিক স্টেট (আইএস)।',\n",
              " 'তারা বিশ্ববিদ্যালয়ে ভর্তি পরীক্ষায় অংশ নেওয়ার প্রস্তুতি নিতে মাবৌদ একাডেমি নামের ওই কোচিং সেন্টারে ক্লাস করছিল।',\n",
              " \"প্রযোজক বারবারা ব্রকোলি বলেছেন, 'এই ছবির গল্পে একেবারে শুরুতে ফিরে যাওয়া হবে।\",\n",
              " 'নিহতদের মধে বেশিরভাগই তরুণ।',\n",
              " 'ইন্ডিয়ান এক্সপ্রেস পত্রিকায় মঙ্গলবার প্রকাশিত এক প্রতিবেদনে একথা বলা হয়েছে।',\n",
              " 'নদের চীনা অংশে ব্যাপক খননের কারণেই এটি হয়েছে।',\n",
              " \"অরুণাচলের কংগ্রেস দলীয় এমপি নিনং ইরিং মোদিকে পাঠানো চিঠিতে লিখেছেন, 'প্রমত্তা সিয়াং (ব্রহ্মপুত্র নদের আঞ্চলিক নাম) নদীর পানি এই নভেম্বর মাসে নোংরা ও কালো হওয়ার অন্য কোনো কারণ নেই।\",\n",
              " 'গত ৩১ অক্টোবর ওই পত্রিকায় প্রকাশিত আরেকটি প্রতিবেদনে চীনের এক হাজার কিলোমিটার সুড়ঙ্গ নির্মাণের পরিকল্পনার কথা উল্লেখ করে বলা হয়েছিল, তিব্বত থেকে হাজার কিলোমিটার সুড়ঙ্গের মাধ্যমে ব্রহ্মপুত্র নদের পানি জিনজিয়াং অঞ্চলে নিয়ে যাওয়ার পরিকল্পনা করছে চীন।',\n",
              " 'তাকে উদ্ধারের জন্য দায়িত্ব দেওয়া হয় জেমস বন্ডকে।',\n",
              " 'জঙ্গি গোষ্ঠীটি বৃহস্পতিবার তাদের আমাক বার্তা সংস্থায় এ দায় স্বীকার করে।',\n",
              " \"আন্তর্জাতিক দলও এ বিষয়টি নিশ্চিত করেছে।'\",\n",
              " 'বাংলাদেশ, ভারত ও চীনের অভিন্ন নদী ব্রহ্মপুত্রের গতিপথ বদলাতে চীন হাজার কিলোমিটারের একটি সুড়ঙ্গ নির্মাণ করছে।',\n",
              " 'হমলাকারী আত্মঘাতী বেল্ট পরে ছিল বলে জানিয়েছে আমাক।',\n",
              " 'অরুণাচলের কংগ্রেস দলীয় এমপি নিনং ইরিং ভারতের প্রধানমন্ত্রী নরেন্দ্র মোদিকে লেখা এক চিঠিতে এ বিষয়টি তুলে ধরেছেন এবং অনতিবিলম্বে এ বিষয়ে ব্যবস্থা নেওয়ার অনুরোধ জানিয়েছেন।',\n",
              " \"ফুকুনাগা বন্ড সিরিজের এই নতুন ছবি নিয়ে বলেন, 'দারুণ এক অভিজ্ঞতার জন্য অপেক্ষা করছি।\"]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev['train']['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9ZPmUgI6bi6",
        "outputId": "572e7e10-23a8-45c1-a4c0-cae88c14097b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dev['train']['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up4KolRV6bi6",
        "outputId": "752b6cca-0192-4d39-edef-ef9092cbf5d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dev['test']['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkaNok9r6bi6",
        "outputId": "c0c7c9b0-647b-4850-ee4d-a6660773ef42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 8\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAG0FOJd6bi6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "model_checkpoint = \"bigscience/bloom-7b1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vncYwjye6bi6",
        "outputId": "b5bd2ded-7ecd-4edf-d7f5-7c552d0bd885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary size: 250680, max sequence length: 1000000000000000019884624838656\n"
          ]
        }
      ],
      "source": [
        "print('vocabulary size: %d, max sequence length: %d' % (tokenizer.vocab_size, tokenizer.model_max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeTFni4R6bi7"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer([\" \".join(x) for x in examples[\"text\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKOojWq96bi7",
        "outputId": "34873ada-b8ef-421e-9246-bc14b4dba6ad",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_dt = dev.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=[\"text\"],\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFrF0Rvt6bi7",
        "outputId": "6cc5d392-9d65-4d12-91cf-8e472611f9ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 31\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 8\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL9tB4pw6bi7"
      },
      "outputs": [],
      "source": [
        "block_size = 256\n",
        "\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skMpEgAA6bi7",
        "outputId": "45eadebb-556d-415d-ad14-f7448fcb20b7",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 11\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 4\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_dataset = tokenized_dt.map(group_texts, batched=True, num_proc=1)\n",
        "lm_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M-IOVGM6bi7",
        "outputId": "43dbfb6c-0abf-475e-f375-8bd4c64a6c88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[711,\n",
              " 281,\n",
              " 127,\n",
              " 2105,\n",
              " 250,\n",
              " 1771,\n",
              " 2340,\n",
              " 18398,\n",
              " 720,\n",
              " 1529,\n",
              " 219,\n",
              " 250,\n",
              " 991,\n",
              " 638,\n",
              " 1529,\n",
              " 219,\n",
              " 711,\n",
              " 281,\n",
              " 126,\n",
              " 2105,\n",
              " 1529,\n",
              " 219,\n",
              " 250,\n",
              " 1781,\n",
              " 1529,\n",
              " 213,\n",
              " 2105,\n",
              " 1529,\n",
              " 213,\n",
              " 1103,\n",
              " 1529,\n",
              " 219,\n",
              " 250,\n",
              " 3571,\n",
              " 281,\n",
              " 127,\n",
              " 2105,\n",
              " 1529,\n",
              " 219,\n",
              " 250,\n",
              " 1726,\n",
              " 281,\n",
              " 126,\n",
              " 2639,\n",
              " 1726,\n",
              " 281,\n",
              " 124,\n",
              " 281,\n",
              " 126,\n",
              " 250,\n",
              " 1017,\n",
              " 711,\n",
              " 1529,\n",
              " 219,\n",
              " 640,\n",
              " 790,\n",
              " 281,\n",
              " 126,\n",
              " 281,\n",
              " 214,\n",
              " 2340,\n",
              " 281,\n",
              " 126,\n",
              " 1093,\n",
              " 1529,\n",
              " 219,\n",
              " 1781,\n",
              " 233429,\n",
              " 2004,\n",
              " 281,\n",
              " 126,\n",
              " 2105,\n",
              " 1103,\n",
              " 250,\n",
              " 2639,\n",
              " 250,\n",
              " 1901,\n",
              " 1529,\n",
              " 212,\n",
              " 1009,\n",
              " 1529,\n",
              " 219,\n",
              " 2105,\n",
              " 250,\n",
              " 1200,\n",
              " 2004,\n",
              " 281,\n",
              " 127,\n",
              " 1009,\n",
              " 18398,\n",
              " 1009,\n",
              " 250,\n",
              " 1009,\n",
              " 1093,\n",
              " 1529,\n",
              " 212,\n",
              " 250,\n",
              " 711,\n",
              " 18398,\n",
              " 2105,\n",
              " 1017,\n",
              " 18398,\n",
              " 965,\n",
              " 720,\n",
              " 1529,\n",
              " 213,\n",
              " 1103,\n",
              " 18398,\n",
              " 2105,\n",
              " 1529,\n",
              " 219,\n",
              " 2105,\n",
              " 250,\n",
              " 1771,\n",
              " 1103,\n",
              " 281,\n",
              " 127,\n",
              " 720,\n",
              " 3027,\n",
              " 250,\n",
              " 711,\n",
              " 1093,\n",
              " 2340,\n",
              " 281,\n",
              " 126,\n",
              " 1103,\n",
              " 1529,\n",
              " 219,\n",
              " 250,\n",
              " 1901,\n",
              " 1529,\n",
              " 212,\n",
              " 1009,\n",
              " 250,\n",
              " 1017,\n",
              " 281,\n",
              " 126,\n",
              " 1453,\n",
              " 281,\n",
              " 126,\n",
              " 2105,\n",
              " 250,\n",
              " 638,\n",
              " 281,\n",
              " 127,\n",
              " 2340,\n",
              " 1529,\n",
              " 223,\n",
              " 965,\n",
              " 281,\n",
              " 127,\n",
              " 4541,\n",
              " 281,\n",
              " 126,\n",
              " 2105,\n",
              " 1529,\n",
              " 219,\n",
              " 2105,\n",
              " 250,\n",
              " 991,\n",
              " 638,\n",
              " 4541,\n",
              " 281,\n",
              " 127,\n",
              " 250,\n",
              " 696,\n",
              " 1529,\n",
              " 213,\n",
              " 5420,\n",
              " 281,\n",
              " 124,\n",
              " 281,\n",
              " 237,\n",
              " 18398,\n",
              " 1771,\n",
              " 250,\n",
              " 1009,\n",
              " 281,\n",
              " 127,\n",
              " 2105,\n",
              " 18398,\n",
              " 965,\n",
              " 281,\n",
              " 126,\n",
              " 249609,\n",
              " 250,\n",
              " 638,\n",
              " 2105,\n",
              " 4932,\n",
              " 1529,\n",
              " 219,\n",
              " 640,\n",
              " 4664,\n",
              " 1529,\n",
              " 213,\n",
              " 638,\n",
              " 1529,\n",
              " 213,\n",
              " 1009,\n",
              " 281,\n",
              " 126,\n",
              " 1771,\n",
              " 281,\n",
              " 126,\n",
              " 2105,\n",
              " 250,\n",
              " 720,\n",
              " 18398,\n",
              " 2105,\n",
              " 281,\n",
              " 127,\n",
              " 1726,\n",
              " 281,\n",
              " 124,\n",
              " 250,\n",
              " 711,\n",
              " 1009,\n",
              " 18398,\n",
              " 5420,\n",
              " 250,\n",
              " 1009,\n",
              " 281,\n",
              " 126,\n",
              " 638,\n",
              " 281,\n",
              " 127,\n",
              " 250,\n",
              " 5420,\n",
              " 18398,\n",
              " 1726,\n",
              " 281,\n",
              " 126,\n",
              " 1009,\n",
              " 281,\n",
              " 127,\n",
              " 1726,\n",
              " 281,\n",
              " 124,\n",
              " 1529,\n",
              " 219,\n",
              " 2340,\n",
              " 250,\n",
              " 638,\n",
              " 18398,\n",
              " 2105,\n",
              " 1529,\n",
              " 219,\n",
              " 1771,\n",
              " 1926,\n",
              " 790,\n",
              " 18398,\n",
              " 2105,\n",
              " 1017,\n",
              " 18398,\n",
              " 965,\n",
              " 720]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_dataset['train']['labels'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSOQWdJL6bi7",
        "outputId": "d33c5f12-dfe6-4533-b89a-57630136c693"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"ত খ ন   ভ য ় ং ক র   ন ত ু ন   প ্ র য ু ক ্ ত ি   ন ি য ় ে   স দ ল ব ল ে   হ া জ ি র   হ ব ে   এ ক   র হ স ্ য ম য ়   ভ ি ল ে ন । 'ত া র া   ব ি শ ্ ব ব ি দ ্ য া ল য ় ে   ভ র ্ ত ি   প র ী ক ্ ষ া য ়   অ ং শ   ন ে ও য ় া র   প ্ র স ্ ত ু ত ি   ন ি ত ে   ম া ব ৌ দ   এ ক া ড ে ম ি   ন া ম ে র   ও ই   ক ো চ ি ং   স ে ন ্ ট া র ে   ক ্ ল া স   ক র ছ ি ল ।এ র   ফ ল ে   ভ া র ত ে র   অ র ু ণ া চ\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(lm_dataset[\"train\"][0][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxzN4A1r6bi7"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VSMfQti6bi8"
      },
      "outputs": [],
      "source": [
        "def print_model_size(mdl):\n",
        "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
        "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
        "    os.remove('tmp.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1KRUv2s6bi8"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHOzTR2k6bi8"
      },
      "outputs": [],
      "source": [
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgO-tJvE6bi8",
        "outputId": "67717ad2-4800-4d63-90b2-4be50919328f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "559214592\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BloomForCausalLM(\n",
              "  (transformer): BloomModel(\n",
              "    (word_embeddings): Embedding(250880, 1024)\n",
              "    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x BloomBlock(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): BloomAttention(\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): BloomMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (gelu_impl): BloomGelu()\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(model.num_parameters())\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq0cpms16bi8"
      },
      "outputs": [],
      "source": [
        "print_model_size(model)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulQlUv1V6bi8"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "target_modules = [\"word_embeddings\",\"h.query_key_value\", \"h.dense\" \"lm_head\"]\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=16,\n",
        "    target_modules= target_modules,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH3MYtUK6bi8"
      },
      "outputs": [],
      "source": [
        "peft_model = get_peft_model(model, config)\n",
        "print_model_size(peft_model)\n",
        "print_trainable_parameters(peft_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeX3PW0U6bi8"
      },
      "outputs": [],
      "source": [
        "model.config.apply_spec_augment = True\n",
        "# model.config.max_length = generation_max_length\n",
        "model.config.dropout = 0.1\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXwS2D4j6bjA"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6kQ7_2H6bjB"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\".\\Bloom_2\\model_peft\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size = 1,\n",
        "    per_device_eval_batch_size = 1,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    overwrite_output_dir = True,\n",
        "    learning_rate=1e-3,\n",
        "    save_strategy = 'epoch',\n",
        "    weight_decay=0.001,\n",
        "    push_to_hub=False,\n",
        "    save_total_limit = 10,\n",
        "    warmup_steps = 10,\n",
        "    dataloader_num_workers = 0,\n",
        "    logging_steps = 5,\n",
        "    load_best_model_at_end = True,\n",
        "#     metric_for_best_model = \"perplexity\",\n",
        "    greater_is_better = False ,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "\n",
        "#     logging_steps=10,\n",
        "#     bf16 = True ,\n",
        "    # bf16 = False\n",
        "#     tf32 = True,\n",
        "    num_train_epochs = 5,\n",
        "    disable_tqdm = True,\n",
        "    report_to = [\"tensorboard\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYqU1IGt6bjB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def compute_metrics(pred):\n",
        "    return math.exp(pred['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3U6D1_06bjB"
      },
      "outputs": [],
      "source": [
        "# Initializing the trainer class object that will do the training\n",
        "# here the data collator will generate the batch of size 64 of train and test data\n",
        "trainer = Trainer(\n",
        "    model = peft_model,\n",
        "    args = training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset = lm_dataset['train'],\n",
        "    eval_dataset = lm_dataset['test'],\n",
        "#     compute_metrics=compute_metrics,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXInk4Ka6bjB",
        "outputId": "d53b9869-0df7-4ca5-de7e-b48e4c4fbdb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.1462, 'learning_rate': 0.0005, 'epoch': 0.83}\n",
            "{'eval_loss': 3.070661783218384, 'eval_runtime': 0.5879, 'eval_samples_per_second': 5.103, 'eval_steps_per_second': 5.103, 'epoch': 1.0}\n",
            "{'loss': 3.0238, 'learning_rate': 0.001, 'epoch': 1.67}\n",
            "{'eval_loss': 3.004868268966675, 'eval_runtime': 0.5917, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 5.071, 'epoch': 2.0}\n",
            "{'loss': 2.9223, 'learning_rate': 0.0008535533905932737, 'epoch': 2.5}\n",
            "{'eval_loss': 2.933964967727661, 'eval_runtime': 0.6023, 'eval_samples_per_second': 4.981, 'eval_steps_per_second': 4.981, 'epoch': 3.0}\n",
            "{'loss': 2.8454, 'learning_rate': 0.0005, 'epoch': 3.33}\n",
            "{'eval_loss': 2.8998947143554688, 'eval_runtime': 0.603, 'eval_samples_per_second': 4.975, 'eval_steps_per_second': 4.975, 'epoch': 4.0}\n",
            "{'loss': 2.7412, 'learning_rate': 0.00014644660940672628, 'epoch': 4.17}\n",
            "{'loss': 2.7407, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "{'eval_loss': 2.892390012741089, 'eval_runtime': 0.6032, 'eval_samples_per_second': 4.974, 'eval_steps_per_second': 4.974, 'epoch': 5.0}\n",
            "{'train_runtime': 35.8862, 'train_samples_per_second': 1.672, 'train_steps_per_second': 0.836, 'train_loss': 2.9032703399658204, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=2.9032703399658204, metrics={'train_runtime': 35.8862, 'train_samples_per_second': 1.672, 'train_steps_per_second': 0.836, 'train_loss': 2.9032703399658204, 'epoch': 5.0})"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SnJF2p06bjB",
        "outputId": "fd2775cb-30fd-4d22-f732-68dc29a23d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.892390012741089, 'eval_runtime': 0.8499, 'eval_samples_per_second': 3.53, 'eval_steps_per_second': 3.53, 'epoch': 5.0}\n",
            "Perplexity: 18.04\n"
          ]
        }
      ],
      "source": [
        "#2 epochs\n",
        "import math\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvzUD4_06bjB"
      },
      "outputs": [],
      "source": [
        "#2 epochs Perplexity: 24.30\n",
        "#3 epochs Perplexity: 23.53\n",
        "#5 epochs Perplexity: 22.68\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HpbvN0m6bjB"
      },
      "source": [
        "#### The train loss achieved is 4.778"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx2hjAbI6bjB"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcNRc4VU6bjB",
        "outputId": "389f561f-b829-4323-84ea-9da7912dd17d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.892390012741089, 'eval_runtime': 0.9009, 'eval_samples_per_second': 3.33, 'eval_steps_per_second': 3.33, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.892390012741089,\n",
              " 'eval_runtime': 0.9009,\n",
              " 'eval_samples_per_second': 3.33,\n",
              " 'eval_steps_per_second': 3.33,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluating on Test data\n",
        "trainer.evaluate(lm_dataset['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC6TcoAe6bjC"
      },
      "source": [
        "#### Test loss is 5.52"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XJFYjIC6bjC"
      },
      "source": [
        "### Creating a pipeline object for text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbGRLKhJ6bjC",
        "outputId": "ae212cd6-e27b-4d96-ec2c-35f09b47295e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Tokenizer_bloom1\\\\tokenizer_config.json',\n",
              " 'Tokenizer_bloom1\\\\special_tokens_map.json',\n",
              " 'Tokenizer_bloom1\\\\tokenizer.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"Tokenizer_bloom1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrxCtZYr6bjC"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "config = PeftConfig.from_pretrained(\".\\\\Bloom_2\\\\model_peft\\\\checkpoint-30\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\".\\\\Tokenizer_bloom1\")\n",
        "model = BloomForCausalLM.from_pretrained(config.base_model_name_or_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5zJ8gQz6bjC",
        "outputId": "ba6de328-7f56-4dc0-a5c3-09def709f3c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method ModuleUtilsMixin.num_parameters of BloomForCausalLM(\n",
              "  (transformer): BloomModel(\n",
              "    (word_embeddings): Embedding(250880, 1024)\n",
              "    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x BloomBlock(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): BloomAttention(\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): BloomMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (gelu_impl): BloomGelu()\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
              ")>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.num_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIfYpGs46bjC"
      },
      "outputs": [],
      "source": [
        "generator = pipeline('text-generation', tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzfHTOb96bjC",
        "outputId": "11c42374-ed6f-4d06-fd21-dd3733aceefa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "আমি বাংলায় গান গাই\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "generating  next word in 3 possible ways\n",
        "1. Greedy Search : chooses the best possible next word based on highest probability from 1 hypothesis\n",
        "2. Beam Search : chooses the high probability next word from n hypothesis\n",
        "3. Random Sampling : chooses random next word from possible hypothesis , however as the temperature is set high , it will\n",
        "   ignore low probability words.\n",
        "'''\n",
        "\n",
        "print(generator('আমি বাংলায় গান', max_length=5)[0]['generated_text'])\n",
        "print(generator('আমার নাম', max_length=5,num_beams = 5)[0]['generated_text'])\n",
        "print(generator('তোমার কি' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot8J28ad6bjD"
      },
      "source": [
        "### Predicting Next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCqQjkyW6bjD"
      },
      "outputs": [],
      "source": [
        "def predict_next():\n",
        "    from transformers import OpenAIGPTTokenizer,OpenAIGPTLMHeadModel,\\\n",
        "    TextDataset,TrainingArguments,Trainer,pipeline,DataCollatorForLanguageModeling\n",
        "    import re\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "    tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")\n",
        "    model = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')\n",
        "    generator = pipeline('text-generation', tokenizer='openai-gpt', model='gpt_model')\n",
        "    while(True):\n",
        "        text = input('Enter the text: ')\n",
        "        length= len(tokenizer.encode(text, return_tensors='pt')[0])\n",
        "\n",
        "        max_length = length+1\n",
        "\n",
        "        print('Next Word: ')\n",
        "        print(generator(text , max_length=max_length)[0]['generated_text'].split(' ')[-1])\n",
        "        print(generator(text , max_length=max_length , num_beams = 5)[0]['generated_text'].split(' ')[-1])\n",
        "        print(generator(text , max_length=max_length , do_sample=True,temperature = 0.7)[0]['generated_text'].split(' ')[-1])\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgVl_a1T6bjE"
      },
      "outputs": [],
      "source": [
        "predict_next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzQGmrIL6bjE"
      },
      "outputs": [],
      "source": [
        "bloom stgcn whisper/wave2vec"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}